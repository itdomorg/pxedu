package cn.gxlx.mr.spark;

import java.util.regex.Pattern;

public final class JavaLocalStream {
    static final Pattern SPACE = Pattern.compile("#");

    public static void main(String[] args) {
        /*
        
        // Create the context with a 1 second batch size    
        SparkConf sparkConf = new SparkConf().setAppName("JavaLocalStream");
        
        sparkConf.setMaster("local[3]");
        sparkConf.setAppName("wordcount");
        System.setProperty("hadoop.home.dir", "D:\\workplugin\\hadoop\\hadoop26");
        
        JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, Durations.seconds(20));
        System.out.println("aaaaaaaaaaaaa");
        
        Map<String, Integer> topicMap = new HashMap<String, Integer>();
        String[] topics = new String[] { "spark-strom" };
        for (String topic : topics) {
        topicMap.put(topic, 3);
        }
        
        JavaPairReceiverInputDStream<String, String> kafkaStream = KafkaUtils.createStream(ssc, "slave01",
        "spark-strom", topicMap);
        
        // Create a JavaReceiverInputDStream on target ip:port and count the    
        // words in input stream of \n delimited text (eg. generated by 'nc')    
        // Note that no duplication in storage level only for running locally.    
        // Replication necessary in distributed scenario for fault tolerance.   
        JavaDStream<String> lines = ssc.textFileStream("e://testdata//spark");
        JavaReceiverInputDStream<String> lines1 = ssc.socketTextStream("192.168.190.209", Integer.parseInt("9999"),
        StorageLevels.MEMORY_AND_DISK_SER);
        
        System.out.println("bbbbbbbbbbbbbbbbbbbbbbb");
        
        JavaDStream<String> words = lines1.flatMap(new FlatMapFunction<String, String>() {
        public Iterable<String> call(String x) {
        return Lists.newArrayList();
        }
        });
        JavaPairDStream<String, Integer> wordCounts = words.mapToPair(new PairFunction<String, String, Integer>() {
        public Tuple2<String, Integer> call(String s) {
        return new Tuple2<String, Integer>(s, 1);
        }
        }).reduceByKey(new Function2<Integer, Integer, Integer>() {
        public Integer call(Integer i1, Integer i2) {
        return i1 + i2;
        }
        });
        System.out.println("cccccccccccccccccccccccccccc");
        wordCounts.print();
        System.out.println(wordCounts.hashCode());
        ssc.start();
        ssc.awaitTermination();
        */}

}
